{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import (\n",
    "    bootstrap,\n",
    "    gmean,\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "from duet.process import *\n",
    "from duet.constants import *\n",
    "from common import *\n",
    "\n",
    "df_prep = preprocess_data(load_raw())\n",
    "unique_suites = df_prep[RF.suite].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV - Relative Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = (\n",
    "    df_prep.groupby(BENCHMARK_ENV_COL)\n",
    "    .agg(\n",
    "        time_count=(RF.time_ns, len),\n",
    "        time_mean=(RF.time_ns, \"mean\"),\n",
    "        time_var=(RF.time_ns, \"var\"),\n",
    "        time_std=(RF.time_ns, \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df_cv[\"CV\"] = df_cv[\"time_std\"] / df_cv[\"time_mean\"]\n",
    "\n",
    "for suite in unique_suites:\n",
    "    fig = px.bar(\n",
    "        df_cv[df_cv[RF.suite] == suite],\n",
    "        x=RF.benchmark,\n",
    "        y=\"CV\",\n",
    "        facet_col=DF.env,\n",
    "        color=RF.type,\n",
    "        barmode=\"group\",\n",
    "        title=f\"Benchmark Time Relative Deviation - {suite}\",\n",
    "    )\n",
    "    fig.update_xaxes(categoryorder=\"category ascending\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.box(\n",
    "    translate(df_cv),\n",
    "    x=RF.suite,\n",
    "    y=\"CV\",\n",
    "    color=RF.type,\n",
    "    facet_col=DF.env,\n",
    "    hover_data=[RF.benchmark],\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"CV\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/cv.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best duet `overlap_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    df_overlap_match = compute_ci(df_prep, np.arange(0.1, 1, 0.1))\n",
    "else:\n",
    "    df_overlap_match = compute_ci(df_prep, [0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = arbiter_ci_contains_zero(df_overlap_match)\n",
    "df = (\n",
    "    df.groupby(by=[DF.env, RF.suite, RF.type, DF.overlap_rate])\n",
    "    .agg(\n",
    "        total_count=(DF.match_ci, \"count\"),\n",
    "        match_count=(DF.match_ci, \"sum\"),\n",
    "        miss_err=(DF.err_ci, np.mean),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df[DF.match_ratio_ci] = df[\"match_count\"] / df[\"total_count\"]\n",
    "\n",
    "fig = px.line(\n",
    "    translate(df),\n",
    "    x=DF.overlap_rate,\n",
    "    y=DF.match_ratio_ci,\n",
    "    color=RF.suite,\n",
    "    facet_col=DF.env,\n",
    "    markers=True,\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"Minimum overlap ratio\",\n",
    "    yaxis_title=\"CI test A/A detection\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/citest_aa_match_by_overlap.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = arbiter_utest(df_prep)\n",
    "df = (\n",
    "    df.groupby(by=[DF.env, RF.suite, RF.type])\n",
    "    .agg(\n",
    "        total_count=(DF.match_utest, \"count\"),\n",
    "        match_count=(DF.match_utest, \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df[DF.match_ratio_utest] = df[\"match_count\"] / df[\"total_count\"]\n",
    "fig = px.bar(\n",
    "    translate(df),\n",
    "    x=RF.suite,\n",
    "    y=DF.match_ratio_utest,\n",
    "    color=RF.type,\n",
    "    facet_col=DF.env,\n",
    "    barmode=\"group\",\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"u-test A/A detection\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/utest_aa_match.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[RF.suite] != \"speccpu\"][DF.match_ratio_utest].mean())\n",
    "print(df[df[RF.suite] == \"speccpu\"][DF.match_ratio_utest].mean())\n",
    "print(\n",
    "    df[(df[RF.suite] == \"speccpu\") & (df[DF.env] == \"bare-metal\")][\n",
    "        DF.match_ratio_utest\n",
    "    ].mean()\n",
    ")\n",
    "print(\n",
    "    df[(df[RF.type] == \"duet\") & (df[RF.suite].isin([\"dacapo\", \"scalabench\"]))][\n",
    "        DF.match_ratio_utest\n",
    "    ].mean()\n",
    ")\n",
    "print(df[df[RF.type] == \"syncduet\"][DF.match_ratio_utest].mean())\n",
    "print(df[df[RF.type] == \"seqn\"][DF.match_ratio_utest].mean())\n",
    "print(df[df[RF.type] == \"duet\"][DF.match_ratio_utest].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ci = df_overlap_match[\n",
    "    df_overlap_match[DF.overlap_rate].isnull()\n",
    "    | df_overlap_match[DF.overlap_rate].isin([0.4])\n",
    "]\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_ci = arbiter_ci_contains_zero(df_ci)\n",
    "df = group_predictions(df_pred_ci, utest=False)\n",
    "fig = px.bar(\n",
    "    translate(df),\n",
    "    x=RF.suite,\n",
    "    y=DF.match_ratio_ci,\n",
    "    facet_col=DF.env,\n",
    "    color=RF.type,\n",
    "    barmode=\"group\",\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"CI test A/A detection\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/citest_aa_match.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[DF.match_ratio_ci].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CI test per benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"type:pairing\"\n",
    "df_ci[type] = df_ci[RF.type] + \":\" + df_ci[DF.overlap_rate].astype(str)\n",
    "\n",
    "for suite in unique_suites:\n",
    "    suite_mask = df_ci[RF.suite] == suite\n",
    "    if suite_mask.any():\n",
    "        fig = px.scatter(\n",
    "            df_ci[suite_mask],\n",
    "            x=\"benchmark\",\n",
    "            y=\"mid\",\n",
    "            error_y=\"err\",\n",
    "            color=type,\n",
    "            facet_col=DF.env,\n",
    "            title=f\"CI - {suite}\",\n",
    "        )\n",
    "        fig.update_xaxes(categoryorder=\"category ascending\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in unique_suites:\n",
    "    fig = px.bar(\n",
    "        df_ci[df_ci[RF.suite] == suite],\n",
    "        x=RF.benchmark,\n",
    "        y=DF.ci_width,\n",
    "        color=type,\n",
    "        facet_col=DF.env,\n",
    "        barmode=\"group\",\n",
    "        title=f\"Relative CI Width comparison - {suite}\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    translate(df_ci),\n",
    "    x=RF.suite,\n",
    "    y=DF.ci_width,\n",
    "    color=RF.type,\n",
    "    facet_col=DF.env,\n",
    "    hover_data=[RF.benchmark],\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"Relative CI width\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/ci_width.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(\n",
    "    df_ci,\n",
    "    columns=[RF.type],\n",
    "    values=DF.ci_width_absolute,\n",
    "    index=[RF.suite, RF.benchmark, DF.env],\n",
    ").reset_index()\n",
    "df[\"sync_improvement\"] = df[\"Sequential\"] - df[\"Synchronous duet\"]\n",
    "df[\"async_improvement\"] = df[\"Sequential\"] - df[\"Asynchronous duet\"]\n",
    "df[\"sync_improvement_relative\"] = (df[\"sync_improvement\"] / df[\"Sequential\"]) * 100\n",
    "df[\"async_improvement_relative\"] = (df[\"async_improvement\"] / df[\"Sequential\"]) * 100\n",
    "df_absolute = df.melt(\n",
    "    id_vars=[RF.suite, RF.benchmark, DF.env],\n",
    "    value_vars=[\"sync_improvement\", \"async_improvement\"],\n",
    "    value_name=\"improvement\",\n",
    ")\n",
    "df_relative = df.melt(\n",
    "    id_vars=[RF.suite, RF.benchmark, DF.env],\n",
    "    value_vars=[\"sync_improvement_relative\", \"async_improvement_relative\"],\n",
    "    value_name=\"improvement\",\n",
    ")\n",
    "\n",
    "for suite in [\"Renaissance\", \"DaCapo\", \"Scalabench\", \"SPEC CPU\"]:\n",
    "    display(\n",
    "        px.bar(\n",
    "            df_absolute[df_absolute[RF.suite] == suite],\n",
    "            x=RF.benchmark,\n",
    "            y=\"improvement\",\n",
    "            color=\"type\",\n",
    "            facet_col=DF.env,\n",
    "            barmode=\"group\",\n",
    "        )\n",
    "    )\n",
    "    display(\n",
    "        px.bar(\n",
    "            df_relative[df_relative[RF.suite] == suite],\n",
    "            x=RF.benchmark,\n",
    "            y=\"improvement\",\n",
    "            color=\"type\",\n",
    "            facet_col=DF.env,\n",
    "            barmode=\"group\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "display(\n",
    "    df.groupby(RF.suite).agg(\n",
    "        sync_relative_mean_improvement=(\"sync_improvement_relative\", \"mean\"),\n",
    "        async_relative_mean_improvement=(\"async_improvement_relative\", \"mean\"),\n",
    "    )\n",
    ")\n",
    "display(\n",
    "    df.groupby(RF.suite).agg(\n",
    "        sync_mean_improvement=(\"sync_improvement\", \"mean\"),\n",
    "        async_mean_improvement=(\"async_improvement\", \"mean\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ci[df_ci[RF.suite] == \"SPEC CPU\"]\n",
    "df[\"mid\"] = df[\"mid\"] / (10**9)\n",
    "df[\"err\"] = df[\"err\"] / (10**9)\n",
    "fig = px.scatter(\n",
    "    translate(df),\n",
    "    x=\"benchmark\",\n",
    "    y=\"mid\",\n",
    "    error_y=\"err\",\n",
    "    color=RF.type,\n",
    "    facet_col=DF.env,\n",
    "    template=\"plotly_white\",\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders={**{DF.env: [\"bare-metal\", \"AWS t3.medium\"]}, **order_type},\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"CI (s)\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/ci_example_benchmark.pdf\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "df = arbiter_ci_contains_zero(df)\n",
    "display(df[df[DF.match_ci] == False])\n",
    "display(df[df[DF.match_ci] == False].shape[0] / 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Backup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These errors are not relative\n",
    "fig = px.box(\n",
    "    df_ci,\n",
    "    x=RF.suite,\n",
    "    y=\"err\",\n",
    "    facet_col=DF.env,\n",
    "    color=RF.type,\n",
    "    hover_data=[RF.benchmark],\n",
    "    color_discrete_map=colormap,\n",
    "    category_orders=orders,\n",
    ")\n",
    "fig = save_fig_facet_col_env(\n",
    "    fig,\n",
    "    xaxis_title=\"\",\n",
    "    yaxis_title=\"CI test error\",\n",
    "    legend_title=\"\",\n",
    "    filename=\"figures/ci_test_error.pdf\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_utest = arbiter_utest(df_prep)\n",
    "df = group_predictions(df_pred_utest, ci=False)\n",
    "px.bar(\n",
    "    df,\n",
    "    x=RF.suite,\n",
    "    y=DF.match_ratio_ci,\n",
    "    facet_col=DF.env,\n",
    "    color=RF.type,\n",
    "    barmode=\"group\",\n",
    "    title=\"Correct A/A detection ratio\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df_prep)\n",
    "\n",
    "df = (\n",
    "    df.groupby(ARTIFACT_COL + RUN_ID_COL)\n",
    "    .agg(\n",
    "        time_count=(RF.time_ns, len),\n",
    "        time_mean=(RF.time_ns, \"mean\"),\n",
    "        time_var=(RF.time_ns, \"var\"),\n",
    "        time_std=(RF.time_ns, \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df[\"CV\"] = df[\"time_std\"] / df[\"time_mean\"]\n",
    "\n",
    "for suite in unique_suites:\n",
    "    fig = px.box(\n",
    "        df[df[RF.suite] == suite],\n",
    "        x=RF.benchmark,\n",
    "        y=\"CV\",\n",
    "        facet_row=DF.env,\n",
    "        color=RF.type,\n",
    "        title=f\"Benchmark Time Relative Deviation per run - {suite}\",\n",
    "    )\n",
    "    fig.update_xaxes(categoryorder=\"category ascending\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ci_syncduet = df_prep[df_prep[RF.type] == \"syncduet\"]\n",
    "if df_ci_syncduet.shape[0] == 0:\n",
    "    print(\"No runs\")\n",
    "    raise StopExecution\n",
    "\n",
    "df_ci_syncduet = compute_ci_pair_speedup(df_ci_syncduet, sample_type=\"run_means\")\n",
    "\n",
    "for suite in unique_suites:\n",
    "    suite_mask = df_ci_syncduet[RF.suite] == suite\n",
    "    if suite_mask.any():\n",
    "        fig = px.scatter(\n",
    "            df_ci_syncduet[suite_mask],\n",
    "            x=RF.benchmark,\n",
    "            y=\"mid\",\n",
    "            error_y=\"err\",\n",
    "            color=DF.env,\n",
    "            title=f\"Syncduet pairwise speedup CI - {suite}\",\n",
    "        )\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('duet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b30613eae93c2d498f6090c9d68b2d616e7f48861c26fb69a68f02e86a44a416"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
